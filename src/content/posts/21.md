---
title: "LinkedIn e Apache Kafka: 7 trilioni di messaggi al giorno"
date: 2025-06-13T05:00:00Z
image: /images/posts/post-21.jpg
categories: 
  - Architecture
draft: false
---

Apache Kafka, una piattaforma open-source per l'elaborazione di flussi di dati in tempo reale, è diventato uno strumento essenziale per le aziende che operano su larga scala.

LinkedIn, che ha sviluppato originariamente Kafka, ne è oggi uno dei principali utilizzatori, gestendo oltre 7 trilioni di messaggi al giorno.

Per sostenere questa mole di dati, LinkedIn ha creato un ecosistema Kafka su misura, affrontando sfide di scalabilità e contribuendo attivamente alla comunità open-source.

Kafka è nato nel 2010 all'interno di LinkedIn per gestire in tempo reale i flussi di dati generati dagli utenti. Il sistema ha avuto un tale successo che è stato open-sourced nel 2011 ed è oggi uno standard industriale.

Nonostante la sua adozione diffusa, LinkedIn continua a essere uno degli utilizzatori più avanzati, con un'infrastruttura che include decine e decine di cluster Kafka, più di 4.000 broker e 7 milioni di partizioni.

Questa infrastruttura deve garantire affidabilità e prestazioni elevate.

Per farlo, LinkedIn ha sviluppato una versione personalizzata di Kafka, includendo patch e miglioramenti specifici per le proprie esigenze. Tuttavia, molte di queste innovazioni vengono anche condivise con la comunità open-source, contribuendo allo sviluppo del progetto Apache Kafka.

#### L'ecosistema Kafka di LinkedIn

I cluster Kafka di LinkedIn sono progettati per gestire miliardi di eventi al giorno, assicurando che ogni informazione venga processata in tempo reale.

Le applicazioni interne si affidano a Kafka per registrare le attività degli utenti, trasmettere messaggi tra diversi servizi e raccogliere metriche di sistema, permettendo all'azienda di analizzare e ottimizzare continuamente le proprie operazioni.

Per facilitare la comunicazione tra i vari componenti del sistema, LinkedIn utilizza strumenti che migliorano l'integrazione e la gestione dei dati.

Ad esempio, il REST Proxy permette anche a servizi non basati su Java di interagire con Kafka, mentre un sistema di gestione degli schemi garantisce che i dati inviati e ricevuti siano sempre coerenti.

Per ottimizzare il flusso di dati tra i vari centri operativi dell'azienda, LinkedIn utilizza una tecnologia di replica, che assicura che le informazioni siano sempre disponibili e aggiornate ovunque servano.

Inoltre, per mantenere il sistema bilanciato e prevenire sovraccarichi, un software interno monitora l'uso delle risorse e ridistribuisce automaticamente il carico quando necessario.

#### Sfide e innovazioni per la scalabilità

Gestire Kafka su questa scala presenta numerose sfide.

LinkedIn deve affrontare problemi di scalabilità, operatività e manutenzione, per cui ha creato release personalizzate di Kafka con patch specifiche per le proprie necessità.

Questo approccio non solo ottimizza le prestazioni, ma arricchisce anche l'intero ecosistema open-source.

Oltre alla gestione interna, LinkedIn è un attivo contributore al progetto Apache Kafka.

Le funzionalità sviluppate internamente, come miglioramenti alla gestione delle partizioni e strumenti di automazione, vengono condivise con la comunità, permettendo ad altre aziende di beneficiare delle innovazioni introdotte.

L'uso di Apache Kafka da parte di LinkedIn rappresenta un esempio di come un sistema open-source possa essere adattato e scalato per supportare operazioni globali.

Grazie a un ecosistema personalizzato e a una gestione attenta delle sfide operative, LinkedIn è in grado di elaborare enormi quantità di dati ogni giorno, garantendo al contempo prestazioni elevate e contribuendo alla crescita della piattaforma Kafka per l'intera comunità tecnologica.